{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bdffd35",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/rycroft-group/math714/blob/main/b_fd_approx/fd_approx.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34427a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessity libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sin, cos, exp\n",
    "\n",
    "# Optional: a library for plotting with LaTeX-like \n",
    "# styles nicer formatted figures\n",
    "# Warning: need to have LaTeX installed\n",
    "import scienceplots\n",
    "plt.style.use(['science'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8698e3",
   "metadata": {},
   "source": [
    "# Finite difference approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8039fd",
   "metadata": {},
   "source": [
    "## Test the second-order accuracy\n",
    "This example tests the finite difference formula that we derive in class using the method of undetermined coefficients, \n",
    "$$\n",
    "D_2 u(\\bar{x}) = u'(\\bar{x}) + \\frac{h^2}{3} u'''(\\bar{x}) + O(h^3),\n",
    "$$\n",
    "is indeed second-order accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d7ec78",
   "metadata": {},
   "source": [
    "### Computing the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58975ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to numerically differentiate\n",
    "# Choose one that has an exact solution for the first-derivative\n",
    "def f(z):\n",
    "    return exp(z)*sin(z)\n",
    "\n",
    "# Initial step size, and position to evaluate the derivative at\n",
    "h = 0.1\n",
    "x = 1\n",
    "\n",
    "# The exact derivative for error comparison\n",
    "dfexact = exp(x)*(cos(x)+sin(x))\n",
    "\n",
    "# Store the results for later analysis\n",
    "results = []\n",
    "\n",
    "# Terminate the while-loop when the step size is sufficiently small\n",
    "while h > 1e-10:\n",
    "\n",
    "    # Compute the derivative using the finite-difference stencil\n",
    "    df = (f(x+2*h)+3*f(x)-4*f(x-h))/(6*h)\n",
    "\n",
    "    # Print the numerical and exact derivatives,\n",
    "    # and the magnitude of absolute error\n",
    "    print(h, df, dfexact, abs(df-dfexact))\n",
    "\n",
    "    # Store the results for later analysis\n",
    "    results.append((h, df, dfexact, abs(df-dfexact)))\n",
    "\n",
    "    # Divide the grid spacing by 2\n",
    "    h *= 0.5\n",
    "\n",
    "# Extract step sizes and absolute error values\n",
    "h_values = [r[0] for r in results]\n",
    "abserror_values = [r[3] for r in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17c652a",
   "metadata": {},
   "source": [
    "### Plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f947802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4), dpi=300)\n",
    "\n",
    "# Plot the absolute error vs step size\n",
    "# in both linear and logarithmic scales\n",
    "ax[0].plot(h_values, abserror_values, color='tab:blue', label='Abs. error (linear)', marker='o')\n",
    "ax[1].loglog(h_values, abserror_values, color='tab:orange', label='Abs. error (log)', marker='o')\n",
    "\n",
    "# Formatting\n",
    "ax[0].set_xlabel('Step size ($h$)')\n",
    "ax[0].set_ylabel('Magnitude of abs. error')\n",
    "ax[0].legend(loc='best')\n",
    "ax[1].set_xlabel('Step size ($h$)')\n",
    "ax[1].legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d722e67",
   "metadata": {},
   "source": [
    "The graph of the results is difficult to interpret (left), because the values of $h$ span many orders of magnitude. A clearer view is achieved by using logartihmic axes (right).\n",
    "\n",
    "For $h$ larger than $10^{-5}$, the data appears to follow a quadratic scaling behavior, as expected for a second-order scheme. For $h$ smaller than $10^{-5}$ numerical roundoff errors dominate and the results become less accurate.\n",
    "\n",
    "**Question**: Why does the absolute error increase once the step size decreases below $10^{-5}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61ce0cd",
   "metadata": {},
   "source": [
    "### Fitting a power law model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fac489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only do fitting when h > 10^-5\n",
    "h_fit = [h for h in h_values if h > 1e-5]\n",
    "abserror_fit = abserror_values[:len(h_fit)]\n",
    "\n",
    "# Perform the power law fit (log-log scale)\n",
    "# y = a h^b â€”> log(y) = log(a) + b log(h)\n",
    "log_h = np.log(h_fit)\n",
    "log_error = np.log(abserror_fit)\n",
    "coefficients = np.polyfit(log_h, log_error, 1)  # Linear fit in log-log space\n",
    "\n",
    "# Print results\n",
    "b, a = coefficients\n",
    "print(f\"Slope: {b}, Intercept: {a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3431fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay the fitted power law\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4), dpi=300)\n",
    "\n",
    "# Plot the absolute error vs step size\n",
    "# in both linear and logarithmic scales\n",
    "ax[0].plot(h_values, abserror_values, color='tab:blue', label='Abs. error (linear)', marker='o')\n",
    "ax[1].loglog(h_values, abserror_values, color='tab:orange', label='Abs. error (log)', marker='o')\n",
    "\n",
    "# Add the overlay power law\n",
    "# y_fit = exp(a + b log(h))\n",
    "ax[1].plot(h_fit, np.exp(a + log_h * b), color='tab:green', label='Power law fit', lw=2)\n",
    "\n",
    "# Formatting\n",
    "ax[0].set_xlabel('Step size ($h$)')\n",
    "ax[0].set_ylabel('Magnitude of abs. error')\n",
    "ax[0].legend(loc='best')\n",
    "ax[1].set_xlabel('Step size ($h$)')\n",
    "ax[1].legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b969f4c1",
   "metadata": {},
   "source": [
    "## Compute the coefficients of a finite-difference formula\n",
    "\n",
    "Find the coefficients of a first-derivative finite-difference formula at $\\bar{x}$ using points $\\{ \\bar{x}-2h, \\bar{x}-h, \\bar{x}, \\bar{x}+h, \\bar{x}+2h \\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1c10ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Points to use in finite difference stencil\n",
    "s = [-2, -1, 0, 1, 2]\n",
    "n = len(s)\n",
    "\n",
    "# Assemble linear system using the transpose of the Vandermonde matrix\n",
    "A = np.fliplr(np.vander(s)).T\n",
    "d = np.zeros((n))\n",
    "d[1] = 1\n",
    "\n",
    "# Solve the linear system and print the coefficients\n",
    "b = np.linalg.solve(A, d)\n",
    "for i in range(len(s)):\n",
    "    print(\"Coeff. of f(x + %gh): %g\" % (s[i], b[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2973aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
